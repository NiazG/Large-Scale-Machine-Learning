{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import math\n",
    "import functools\n",
    "import pyspark.sql.functions as pyf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Python Spark SQL basic example\") \\\n",
    "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clickstream = spark.read.options(delimiter='\\t', \n",
    "                                    header='True', \n",
    "                                    inferSchema='True').csv('hdfs:/data/lsml/sga/clickstream.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "errors = clickstream[clickstream.event_type.contains(\"error\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there can be more than 1 error for each session. \n",
    "# We can reduce the amount of errors as we don't need to consider others after the first error\n",
    "error_1 = errors.groupBy(\"user_id\", \"session_id\") \\\n",
    "                .agg(pyf.min(errors.timestamp).alias(\"error_1\")) \\\n",
    "                .withColumnRenamed('user_id','user_id_err') \\\n",
    "                .withColumnRenamed('session_id','session_id_err')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_joined = clickstream.join(error_1, \n",
    "                                 [clickstream.user_id == error_1.user_id_err,\n",
    "                                 clickstream.session_id == error_1.session_id_err], how='leftouter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_errors = errors_joined.filter((errors_joined.error_1.isNull()) |\n",
    "                                          (errors_joined.timestamp <= errors_joined.error_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notice board:\n",
    "\n",
    "* the correct route can be taken by grouping the data by the event_type when it is 'page'. \n",
    "* user is anyway needs to access the page (event_type) and after that the status can be different as 'event' or 'error'\n",
    "\n",
    "### So to achieve the result:\n",
    "* we need to group by the event_type == 'page' \n",
    "* collect the list of routes \n",
    "* use concat_ws to join them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_errors = filtered_errors[filtered_errors.event_type == 'page']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "routes = filtered_errors.groupby(\n",
    "    'user_id', 'session_id').agg( pyf.collect_list('event_page').alias('route')) \\\n",
    "     .groupBy('route') \\\n",
    "       .agg(\n",
    "           pyf.count('user_id').alias('count')).orderBy(pyf.desc('count'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_routes = routes.withColumn('route', pyf.concat_ws(\"-\", routes['route']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_routes.toPandas().head(30).to_csv('niiaz_lsml_dataframe.tsv', sep='\\t', encoding='utf-8', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Great job! Secret keyword is 'AwfulDavros'\r\n"
     ]
    }
   ],
   "source": [
    "! curl -d \"$(cat niiaz_lsml_dataframe.tsv)\" hadoop2-00.yandex.ru:8008/sga/task_spark-df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hive. SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clickstream.createOrReplaceTempView('clickstream')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "error_1 = spark.sql(\"select user_id, session_id, \\\n",
    "min(timestamp) error_1 from clickstream where instr(lower(event_type), 'error') != 0 group by user_id, session_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "error_1.createOrReplaceTempView('error_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filtered_data = spark.sql (\"select cl.* from clickstream cl left join error_1 err1 on \\\n",
    "cl.user_id = err1.user_id and cl.session_id = err1.session_id \\\n",
    "where (err1.error_1 is null or cl.timestamp <= err1.error_1) and event_type == 'page'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filtered_data.createOrReplaceTempView('filtered_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_routes = spark.sql(\"select route, count(*) as total from \\\n",
    "                (select user_id, session_id, concat_ws('-', collect_list(event_page)) as route \\\n",
    "                        from filtered_data group by user_id, session_id)\\\n",
    "                            group by route order by total desc limit 30\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|               route|total|\n",
      "+--------------------+-----+\n",
      "|                main|39250|\n",
      "|        main-tariffs| 6524|\n",
      "|           main-news| 6264|\n",
      "|        main-archive| 5841|\n",
      "|         main-family| 4849|\n",
      "|        main-digital| 4211|\n",
      "|          main-bonus| 3489|\n",
      "|   main-tariffs-news| 1185|\n",
      "|   main-news-tariffs| 1130|\n",
      "|main-tariffs-archive| 1037|\n",
      "|   main-news-archive|  998|\n",
      "|   main-archive-news|  992|\n",
      "|main-archive-tariffs|  990|\n",
      "| main-family-tariffs|  921|\n",
      "|    main-news-family|  916|\n",
      "| main-tariffs-family|  913|\n",
      "|    main-family-news|  874|\n",
      "| main-archive-family|  814|\n",
      "|   main-news-digital|  793|\n",
      "| main-family-archive|  769|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_routes.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_routes.toPandas().head(30).to_csv('niiaz_lsml_sql.tsv', sep='\\t', encoding='utf-8', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Great job! Secret keyword is 'HiveMind'\r\n"
     ]
    }
   ],
   "source": [
    "! curl -d \"$(cat niiaz_lsml_sql.tsv)\" hadoop2-00.yandex.ru:8008/sga/task_hive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clickstream = spark.read.option(\"delimiter\", \"\\t\")\\\n",
    "                                    .option(\"header\", \"true\")\\\n",
    "                                    .csv('/data/lsml/sga/clickstream.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "error_1 = clickstream.rdd.map(lambda x: [x[0], x[1], x[2], 'error', x[4]] \n",
    "                              if 'error' in str(x[2]).lower() \n",
    "                              else [x[0], x[1], x[2], x[3], x[4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "err = error_1.filter(lambda x: x[2] == 'page' or \"error\" in x[2].lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "err2 = err.map(lambda x: [(x[0], x[1]), [x[3]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('562', '507'), ['main']],\n",
       " [('562', '507'), ['error']],\n",
       " [('562', '507'), ['family']],\n",
       " [('562', '507'), ['main']],\n",
       " [('562', '507'), ['news']]]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "err2.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "err3 = err2.reduceByKey(lambda x, y: x + y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('951', '1235'), ['main', 'bonus', 'main']),\n",
       " (('478', '1888'), ['main', 'archive']),\n",
       " (('900', '805'), ['main', 'tariffs', 'news', 'main']),\n",
       " (('129', '1124'), ['main', 'news', 'family', 'spravka', 'archive', 'bonus']),\n",
       " (('717', '1096'),\n",
       "  ['main',\n",
       "   'tariffs',\n",
       "   'news',\n",
       "   'archive',\n",
       "   'bonus',\n",
       "   'archive',\n",
       "   'news',\n",
       "   'archive',\n",
       "   'family',\n",
       "   'bonus',\n",
       "   'archive'])]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "err3.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def route(line):\n",
    "    route = []\n",
    "    if len(line) == 1:\n",
    "        return line[0]\n",
    "    route.append(line[0])\n",
    "    for word in range(1,len(line)):\n",
    "        if line[word] != 'error':\n",
    "            if line[word] == route[-1]:\n",
    "                continue\n",
    "            route.append(line[word])\n",
    "        else:\n",
    "            break\n",
    "    return \"-\".join(route)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "err4 = err3.map(lambda x: (route(x[1]), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('main', 39623),\n",
       " ('main-tariffs', 6583),\n",
       " ('main-news', 6330),\n",
       " ('main-archive', 5907),\n",
       " ('main-family', 4883),\n",
       " ('main-digital', 4252),\n",
       " ('main-bonus', 3519),\n",
       " ('main-tariffs-news', 1195),\n",
       " ('main-news-tariffs', 1149),\n",
       " ('main-tariffs-archive', 1039),\n",
       " ('main-news-archive', 1018),\n",
       " ('main-archive-news', 1003),\n",
       " ('main-archive-tariffs', 1001),\n",
       " ('main-family-tariffs', 922),\n",
       " ('main-news-family', 921),\n",
       " ('main-tariffs-family', 911),\n",
       " ('main-family-news', 876),\n",
       " ('main-archive-family', 819),\n",
       " ('main-news-digital', 793),\n",
       " ('main-tariffs-main', 786),\n",
       " ('main-family-archive', 774),\n",
       " ('main-digital-news', 757),\n",
       " ('main-tariffs-digital', 756),\n",
       " ('main-digital-tariffs', 731),\n",
       " ('main-archive-digital', 719),\n",
       " ('main-spravka', 709),\n",
       " ('main-news-main', 696),\n",
       " ('main-digital-archive', 684),\n",
       " ('main-tariffs-bonus', 670),\n",
       " ('main-archive-main', 623)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "routes = err4.reduceByKey(lambda x,y: x + y).sortBy(lambda x: x[1], ascending=False).take(30)\n",
    "routes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_routes = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in routes:\n",
    "    final_routes += '%s\\t%s\\n' % (i[0], i[1])\n",
    "\n",
    "with open('niiaz_lsml_RDD.tsv', 'w') as f:\n",
    "    f.write(final_routes[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Great job! Secret keyword is 'TheSilenceOfPandora'\r\n"
     ]
    }
   ],
   "source": [
    "! curl -d \"$(cat niiaz_lsml_RDD.tsv)\" hadoop2-00.yandex.ru:8008/sga/task_spark-rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
